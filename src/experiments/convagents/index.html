<!DOCTYPE html>
<html>
<head>

<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
<meta name="description" content="Dante Tam - Architect of both software and buildings, 4X strategy game dev, CS Berkeley '18, graphics, 3D models.">
<meta name="author" content="Dante Tam">
<meta name="keywords" content="Dante Tam, UC Berkeley, Twitter, Machine Learning">
<link rel="icon" href="./favicon.ico">

<title>Stella: Conversational Agents</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<link href="ipynb.css" rel="stylesheet">

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<style>
body {
  font-family: 'Roboto', serif;
  font-size: 14px;
}

h3 {
  text-align: center;
  margin: auto;
}

.navbar {
  display: block;
  background-color: white;
}

.dropdown.active {
  background-color: black;
  color: rgba(50,100,255);
}
</style>

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>

  <nav class="navbar navbar-intro navbar-fixed-top navie navbar-fixed-side navbar-fixed-side-left">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar" style="width: 100%; float: left; overflow: visible; padding: 20px 20px;">
          <span class="icon-bar">Menu</span>
          <span class="sr-only">Toggle navigation</span>
        </button>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-intro">
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">@dantetam<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li><a href="https://github.com/dantetam" target="_blank"><img src="/src/images/github-octocat.png" style="width: 20px; height: 20px;"></img> GitHub</a></li>
              <li><a href="mailto:dante.tam1@gmail.com" target="_blank">E-mail</a></li>
              <li><a href="https://www.linkedin.com/in/daptam" target="_blank"><img src="/src/images/linkedin.png" style="width: 20px; height: 20px;"></img> LinkedIn</a></li>
            </ul>
          </li>
          <li><a href="/">Home</a></li>
          <li><a href="/src/projects.html">Personal Projects</a></li>
          <li><a href="/design/index.html">Design</a></li>
          <!--<li><a href="./src/writings.html">Writings</a></li>-->
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Technical Drawings<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Design</li>
              <li><a href="/src/opstrykon_gdd.pdf">Game Design Document</a></li>
              <li><a href="/src/drawings.html"><img src="/src/images/thrumbo-icon.jpg" style="width: 20px; height: 25px;"></img> Technical Drawings</a></li>
            </ul>
          </li>
          <li><a href="/src/courses.html">Courses</a></li>
          <li><a href="/src/resume.pdf">Resume</a></li>
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Experiments<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Design and Data</li>
              <li><a href="/src/experiments/stella/index.html" target="_blank"><img src="/src/images/stella_hexagon.png" style="width: 20px; height: 20px;"></img> Stella AI (NLP, ML)</a></li>
              <li><a href="/src/experiments/resume/index.html"><img src="/src/images/resume-script-icon.png" style="width: 20px; height: 20px;"></img> Interactive Resume (d3.js)</a></li>
              <li><a href="/src/experiments/datavisual/index.html"><img src="/src/images/ship.png" style="width: 20px; height: 20px;"></img> Data Visualization (d3.js)</a></li>
              <li><a href="/src/experiments/testglwebsite/src/index.html">Graphics (WebGL)</a></li>
              <li role="separator" class="divider"></li>
              <li><a href="#"></a></li>
              <li><a href="#"></a></li>
            </ul>
          </li>
          <li class="dropdown active">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Writings<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Computer Science</li>
              <li><a href="/src/experiments/twitter/index.html"><img src="/src/images/Twitter_Logo_Blue.png" style="width: 20px; height: 20px;"></img> Twitter and ML</a></li>
              <li><a href="/src/experiments/neuralnetwork/index.html">Neural Networks</a></li>
              <li role="separator" class="divider"></li>
            </ul>
          </li>
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>

<div class="container">

  <div class="intro" style="margin-left: 10%; margin-right: 10%;">
    <br>
    <br>
    <h3>Stella: Problem Solving with Conversational Agents</h3>
    <br>
    <p><i>Dante Tam, 5/29/2017</i></p>
    <br>
		<p>In this article, we work through a complicated, intricate computer science problem. We begin by analyzing it, brainstorming and implementing solutions,
		and then testing those solutions on clearly defined tests and metrics, while maintaining best practices and good software architecture.</p>
		<br>
		<p><b>Stating the problem:</b> My conversational agent, <a href="/src/experiments/stella/">Stella</a>, takes in a text command, and needs to return the appropriate action.
		Given a list of actions, this is a relatively easy task for a human. However, it is much harder for computers to see grammatical structures,
		word contexts, etc.</p>
		<br>
		<p>In machine learning, this is called a classification problem. 
			For review, a classification asks given some data point $X_i$, what is the actual class or category $y_i$?
			In this case, our input data is a sentence, and our possible class choices are the various commands. For example,</p>
		<br>
		<p>$$"Please\; show\; my\; finances."\;\Rightarrow \;the\; finance\; command$$</p>
		<br>
		<p><b>First Approach, Text Similarity:</b> We model every command as having some important keywords. The more keywords the command and input share,
		the more likely the command is correct. We extend this to include synonyms of the words present.
		Technically, we achieved this using WordNet, a collection of English words organized into a graph.
		Words that are similar to each other i.e. synonyms, are connected together. We analyzed the similarity of two words by their degrees of connection.
			Much like how LinkedIn shows you more of your closer friends and 1st degree connections, we prioritized first degree synonyms.
		We also give less but significant priority to similarity of defintions and sentence usages i.e. dictionary entries. </p>
		<br>
		<p><b>Second Approach, Zero-One Encoded Vectors w/ Softmax Regression:</b> We represent the inputs as vectors, and the commands as numbered labels.
		The problem transforms below, from the first type to the second:</p>
		<br>
		<p>$$"Please\; show\; my\; finances."\;\Rightarrow \;the\; finance\; command$$</p>
		<p>$$...$$</p>
		<p>$$[0,0,1,0,1,1,1,...]\;\Rightarrow 17$$</p>
		<br>
		<p>Simply put, we want to find a device that turns the sentence into a label. Mathematically, our goal is to find a vector $w$ such that</p>
		<br>
		<p>$$Xw = \hat{y} \approx y \Leftrightarrow minarg_w \vert \vert Xw - y \vert \vert_2^2$$</p>
		<br>
		<p>where $\hat{y}$ is our best guess. We use a method called softmax regression which achieves close to the goal. Google's machine learning library
		TensorFlow helps us greatly with this task.</p>
		<br>
		<p>To get the sentences as vectors, we collect all the unique words, numbered $1$ to $V$. Then every sentence can be represented as a vector $s$ of length $V$,
		such that $s_i = 1$ means that the sentence contains the $ith$ word, otherwise $s_i = 0$. For example,</p>
		<br>
		<p>$$"Please\; show\; my\; finances.",\; "Show\; my\; citations."$$</p>
		<p>$$Please \Leftrightarrow 1, show \Leftrightarrow 2, my \Leftrightarrow 3, finances \Leftrightarrow 4, citations \Leftrightarrow 5$$</p>
		<p>$$[1,1,1,1,0],\;[0,1,1,0,1]$$</p>
		<br>
		<p>Overall, this approach had near 73% validation accuracy, and while quite neat, was not strong enough for our applications.</p>
		<br>
		<p><b>Third Approach, Convolutional Neural Networks for Sentence Classification:</b> We use a convolutional neural network (CNN) on a large sentence vector, 
			as described in the <a href="http://www.aclweb.org/anthology/D14-1181">research paper of the same name</a> (Yoon Kim, 2014).
		We use word2vec, a tool developed which converts words into vectors of length $k$, such that similar words have similar vectors.
		Sentences are now $n$ by $k$ matrices, where $n$ is the maximum length of all sentences and $k$ is the dimension from earlier.
		This essentially gives us an image, which is processed well by CNNs. 
		For regular images, CNNs can become edge detectors, brightness detectors, and so on, just as our CNN can begin to recognize large, semi-abstract concepts
		such as grammatical structures, word contexts, etc.</p>
		<br>
		<p>This method was state of the art in 2014 and not surprisingly it fared well, scoring 97% training accuracy.</p>
		<br>
		<p>We finally have an algorithm for our conversational agent, Stella, which takes in user requests and completes the appropriate action.
		It is a robust solution, scoring very highly on our validation tests. It is extensible, as we can add many more classes and commands and training data.
		It is organized into its own Pythom module, which can be called in a desktop application, web server, etc. It is a good solution.</p>
		<br>
		<br>
		<br>

</div>
</div>

</body>
</html>
